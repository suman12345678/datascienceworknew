{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon food review dataset apply SVM\n",
    "\n",
    "Data set from https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "# Objective\n",
    "Try predicting review using SVM random and grid search and different value of lambda and C\n",
    "\n",
    "# Import data and libraries\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\suman\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "con = sqlite3.connect('database.sqlite') \n",
    "\n",
    "#get only +ve and -ve review \n",
    "raw_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3\"\"\", con) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data=raw_data\n",
    "# Score>3 a positive rating, and score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "\n",
    "filtered_data.sample(5)\n",
    "filtered_data['Score'].value_counts()\n",
    "\n",
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries for same profilename,userid, time, text and take first element \n",
    "sorted_data=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    16864\n",
       "negative     3136\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take only 5000 \n",
    "#clean_data=sorted_data.sample(frac=1).groupby('Score').head(400)\n",
    "_ , clean_data = train_test_split(sorted_data, test_size = 20000, stratify = sorted_data['Score'] )\n",
    "clean_data['Score'].value_counts()\n",
    "#print(clean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73332     b'love bought tri mine kid love snack crunchi ...\n",
       "275996    b'tri sinc sale happi bought ive never tri lar...\n",
       "Name: CleanedText, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean html tag and punctuation\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "#substitute html tag and punctuation\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "#print(sno.stem('tasty'))\n",
    "\n",
    "i=0\n",
    "str1=' '\n",
    "mystop={'of','four','one','would'}\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "#Create new catagory as Cleanedtext after removing htmltag and punctuation and uppercase and word length >2\n",
    "for sent in clean_data['Text'].values:\n",
    "    #change later\n",
    "    #sent=sent[:20]\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if((cleaned_words.lower() not in stop) & (cleaned_words.lower() not in mystop)):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (clean_data['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(clean_data['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1\n",
    " \n",
    "clean_data['CleanedText']=final_string\n",
    "#store for future use\n",
    "#conn = sqlite3.connect('clean_data.sqlite')\n",
    "#c=conn.cursor()\n",
    "#conn.text_factory = str\n",
    "#clean_data.to_sql('Reviews1', conn, flavor=None, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)\n",
    "#con = sqlite3.connect('clean_data.sqlite') \n",
    "#clean_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews1 WHERE Score != 3\"\"\", con) \n",
    "#clean_data['CleanedText'].sample(15)\n",
    "print(clean_data.shape)\n",
    "#Sort data on timestamp\n",
    "clean_data=clean_data.sort_values(by=['Time'],ascending=False)\n",
    "#clean_data\n",
    "clean_data['CleanedText'].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X_train, X_test, y_train , y_test  (14000,) (6000,) (14000,) (6000,)\n",
      "positive and negative review in train and test\n",
      " positive    11949\n",
      "negative     2051\n",
      "Name: Score, dtype: int64 \n",
      " positive    4915\n",
      "negative    1085\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x=clean_data['CleanedText'].values\n",
    "y = clean_data['Score']\n",
    "n=x.shape[0]\n",
    "n1=int(n*.3)\n",
    "X_test_raw = x[0:n1]\n",
    "X_train_raw= x[n1:n+1]\n",
    "y_test=y[0:n1]\n",
    "y_train=y[n1:n+1]\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train_raw.shape, X_test_raw.shape,y_train.shape,y_test.shape)\n",
    "print(\"positive and negative review in train and test\\n\",y_train.value_counts(),\"\\n\",y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BOW and try linear kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 15385) (6000, 15385)\n"
     ]
    }
   ],
   "source": [
    "#now convert CleanedText to TDM\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "X_train = count_vect.fit_transform(X_train_raw)\n",
    "\n",
    "#use the same vectors to convert test data\n",
    "X_test=count_vect.transform(X_test_raw)\n",
    "print(X_train.get_shape(),X_test.get_shape())\n",
    "\n",
    "#print(final_counts[0,:])# this is stored like dict format only non zero values. sparse matrix\n",
    "#x = pd.DataFrame(final_counts.toarray())#this is stored like dataframe format all 0 and non zero values. dense matrix\n",
    "# sparse matrix in csr format works faster compare to dense format\n",
    "#print(x.shape,x.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X_train, X_test, y_train , y_test  (14000, 15385) (6000, 15385) (14000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Use scale of train and apply to test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "encoded_column_vector = label_binarize(y_train, classes=['negative','positive']) # negative will be 0 and positive will be 1\n",
    "encoded_labels = np.ravel(encoded_column_vector) # Reshape array\n",
    "y_train=encoded_labels\n",
    "\n",
    "encoded_column_vector = label_binarize(y_test, classes=['negative','positive']) # negative will be 0 and positive will be 1\n",
    "encoded_labels = np.ravel(encoded_column_vector) # Reshape array\n",
    "y_test=encoded_labels\n",
    "\n",
    "\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "#print(\"positive and negative review in train and test\\n\",y_train.value_counts(),\"\\n\",y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with linear karnel and grid search\n",
      " SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "confusion matrix\n",
      " Predicted     1   All\n",
      "Actual               \n",
      "0          1085  1085\n",
      "1          4915  4915\n",
      "All        6000  6000\n",
      "Test accuracy using linear kernel 0.819166666667\n",
      "     C  accuracy_test  accuracy_train  fscore_test  fscore_train gamma  \\\n",
      "0  0.1       0.819167          0.8535     0.620973      0.630587  auto   \n",
      "\n",
      "   kernel             type  \n",
      "0  linear  Grid search BOW  \n"
     ]
    }
   ],
   "source": [
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import validation_curve\n",
    "    \n",
    "   \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['linear']\n",
    "gamma=['auto']\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with linear karnel and grid search\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "aa=pd.DataFrame({'type':['Grid search BOW'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel\",model.score(X_test, y_test))\n",
    "# Print coefficients\n",
    "# check no of parameter\n",
    "#w = model.coef_\n",
    "#print('Count of non zero element in coefficient',np.count_nonzero(w))\n",
    "#print('Model test score',model.score(X_test,y_test))\n",
    "print(aa)\n",
    "#Plot accuracy with C\n",
    "#create plot for training and test validation\n",
    "# Calculate accuracy on training and test set using range of parameter values\n",
    "C=[1,10,50,100,150,200,500]\n",
    "param_range=[1,10,50,100,150,200,500]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(), X_train, y_train, param_name=\"C\",param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With linear SVM for different C value\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(1,500)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "C=[.1,.5,.8,1,2]\n",
    "kernel=['linear']\n",
    "gamma=['auto']\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using linear kernel and random search \\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix \\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "bb=pd.DataFrame({'type':['Random Search BOW'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "print(aa)\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with linear kernel with random and grid search\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "    \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search BOW'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel\",model.score(X_test, y_test))\n",
    "# Print coefficients\n",
    "# check no of parameter\n",
    "#w = model.coef_\n",
    "#print('Count of non zero element in coefficient',np.count_nonzero(w))\n",
    "#print('Model test score',model.score(X_test,y_test))\n",
    "\n",
    "\n",
    "C=[.1,.5,.8,1,2,5]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search \\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.9,.7,.5,.3,.1,1,2,5]\n",
    "param_range=[.9,.7,.5,.3,.1,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With linear SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.1,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "final_counts = tf_idf_vect.fit_transform(X_train_raw)\n",
    "#use the same vectors to convert test data\n",
    "X_test=count_vect.transform(X_test_raw)\n",
    "print(X_train.get_shape(),X_test.get_shape())\n",
    "#Use scale of train and apply to test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "  \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search using TFIDF\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel TFIDF\",model.score(X_test, y_test))\n",
    "# Print coefficients\n",
    "# check no of parameter\n",
    "#w = model.coef_\n",
    "#print('Count of non zero element in coefficient',np.count_nonzero(w))\n",
    "#print('Model test score',model.score(X_test,y_test))\n",
    "\n",
    "\n",
    "C=[.1,.5,.8,1,2,5,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search TFIDF\\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix test\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "bb=pd.DataFrame({'type':['Random search TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.05,.03,.02,.01,1,2,5]\n",
    "param_range=[.05,.03,.02,.01,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.5,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy with C with optimum gamma\n",
    "C=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "param_range=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',gamma=optimumgamma), X_train, y_train, param_name=\"C\", \\\n",
    "                                              param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different C value for optimum gamma\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.01,20)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AVG W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "import gensim\n",
    "#convert W2V train data\n",
    "i=0\n",
    "#create a list of list to be used in W2V \n",
    "list_of_sent_train=[]\n",
    "for sent in X_train_raw:  #clean_data['CleanedText'].values:\n",
    "    filtered_sentence=[]\n",
    "    #sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        #for cleaned_words in cleanpunc(w).split():\n",
    "         for cleaned_words in w.split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower().decode('utf8'))\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_train.append(filtered_sentence)\n",
    "#convert each sentence's words to a vector of 50 dimension. Dont construct vec if word doesnot occur 5 times. And for each word construct 50 dimension vector\n",
    "#and 4 core processor\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent_train,min_count=5,size=50, workers=4)   \n",
    "\n",
    "# average Word2Vec\n",
    "# for each sentence make average of vectors by (vectors of each words)/(total no of words)\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent_train: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_train.append(sent_vec)  \n",
    "\n",
    "    \n",
    "#convert W2V test data\n",
    "i=0\n",
    "#create a list of list to be used in W2V \n",
    "list_of_sent_test=[]\n",
    "for sent in X_test_raw:  #clean_data['CleanedText'].values:\n",
    "    filtered_sentence=[]\n",
    "    #sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        #for cleaned_words in cleanpunc(w).split():\n",
    "         for cleaned_words in w.split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower().decode('utf8'))\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_test.append(filtered_sentence)\n",
    "#convert each sentence's words to a vector of 50 dimension. Dont construct vec if word doesnot occur 5 times. And for each word construct 50 dimension vector\n",
    "#and 4 core processor\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent_test,min_count=5,size=50, workers=4)   \n",
    "\n",
    "# average Word2Vec\n",
    "# for each sentence make average of vectors by (vectors of each words)/(total no of words)\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_test.append(sent_vec)  \n",
    "\n",
    "# try\n",
    "X_train = pd.DataFrame(sent_vectors_train)\n",
    "X_test = pd.DataFrame(sent_vectors_test)\n",
    "\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "  \n",
    "# Use grid search\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search using TFIDF\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search AVG W2V'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "print(\"Test accuracy using linear kernel AVG W2V\",model.score(X_test, y_test))\n",
    "C=[.1,.5,.8,1,2,5,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search AVG W2V\\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "bb=pd.DataFrame({'type':['Random search AVG W2V'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# Plot\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.05,.03,.02,.01,1,2,5]\n",
    "param_range=[.05,.03,.02,.01,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.5,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy with C with optimum gamma\n",
    "C=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "param_range=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',gamma=optimumgamma), X_train, y_train, param_name=\"C\", \\\n",
    "                                              param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different C value for optimum gamma\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.01,20)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AVG W2V TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "final_tf_idf=tf_idf_vect.fit_transform(X_train_raw)\n",
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors_train = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "#calculate avg tfidf score for each sentences \n",
    "for sent in list_of_sent_train: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]#calculate w2v for each word\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = final_tf_idf[row, tfidf_feat.index(word)]#get tfidf score of each word \n",
    "            sent_vec += (vec * tf_idf) # multiply vec with tfidf of each word and cumulative add of words in each sentence\n",
    "            weight_sum += tf_idf # also add tfidf sums in each sentence\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_train.append(sent_vec)\n",
    "    row += 1\n",
    "#tfidf_sent_vectors.\n",
    "\n",
    "# do for test\n",
    "final_tf_idf=tf_idf_vect.transform(X_test_raw)\n",
    "tfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "#calculate avg tfidf score for each sentences \n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]#calculate w2v for each word\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = final_tf_idf[row, tfidf_feat.index(word)]#get tfidf score of each word \n",
    "            sent_vec += (vec * tf_idf) # multiply vec with tfidf of each word and cumulative add of words in each sentence\n",
    "            weight_sum += tf_idf # also add tfidf sums in each sentence\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_test.append(sent_vec)\n",
    "    row += 1\n",
    "\n",
    "X_train = pd.DataFrame(tfidf_sent_vectors_train)\n",
    "X_test = pd.DataFrame(tfidf_sent_vectors_test)\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "\n",
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "  \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search using TFIDF\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search AVG W2V TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel TFIDF\",model.score(X_test, y_test))\n",
    "# Print coefficients\n",
    "# check no of parameter\n",
    "#w = model.coef_\n",
    "#print('Count of non zero element in coefficient',np.count_nonzero(w))\n",
    "#print('Model test score',model.score(X_test,y_test))\n",
    "\n",
    "\n",
    "C=[.1,.5,.8,1,2,5,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search TFIDF\\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Random search AVG W2V TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# Plot\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.05,.03,.02,.01,1,2,5]\n",
    "param_range=[.05,.03,.02,.01,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.5,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy with C with optimum gamma\n",
    "C=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "param_range=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',gamma=optimumgamma), X_train, y_train, param_name=\"C\", \\\n",
    "                                              param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different C value for optimum gamma\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.01,20)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "The below steps are taken to complete this\n",
    "Only !=3 reviews are taken Mark >3 as positive and <3 as negative. Sort data as per product id in ascending order Deduplication of entries for same profilename,userid, time, text and take first element Get stratified sampling of 50k data Clean html and punctuation Convert to uppercase and word<3 are rejected data sorted on time Split the data in train and test to 70:30\n",
    "\n",
    "BOW\n",
    "BOW BOW vec created using train data test data is converted using above X is standarize on train and same applied to test y is converted to 1 and 0 from positive and negative \n",
    "\n",
    "do grid search and random search for different value of kernel and C best model is established with best hyperparameter. model metric is stored in dataframe and crosstable is printed.Plot cv error with C and penalty\n",
    "\n",
    "TFIDF \n",
    "form tfidf vec using train same is used in test to convert rest are same\n",
    "\n",
    "\n",
    "AVG W2V \n",
    "gensim is used to convert train and test text to \n",
    "\n",
    "W2V AVG TFIDF\n",
    "form tfidf vec using train same is used in test to convert. TFIDF and gensim is used to convert test data. rest are same\n",
    "\n",
    "The scores are below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
