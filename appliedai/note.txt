linear algeber generalize n-D problem
any coordinate can be represented as a vector
row vec 1*n col vec n*1
vec multiplicatio (dot and cross)
a=[a1 a2 a3.. an]
b=[b1 b2 b3.. bn]
a.b(dot product)=a1*b1+a2*b2+....an*bn=aT(transpose)b=||a||||b||costheta  [this is true for n dim vector]
projecttion of vec a on b is = a.b/||b||  = a.b/||a||
default vector is column vector
if a and b are perpendicular aT(transpose)b=0  so if a has some value all points on vector b are perpendicular to a so aTb is equation of a plane passing thr origin
distance of a point p(p1 p2 p3 p4...) from a plane wTx=0 is wTp/||w||
elicpises xsq/asq+ysq/bsq=1   circle xsq+ysq=rsq

random variable(continuous and discreate)

set is not indexable
15//2=7(closer integer)
bitwise operator==> convert to binary then calculate bitwise
a=5 b=5 print(a is b)==> True
0 None False are false
break(come out of loop) continue(start with new iteration in the loop)



nirmalization make 0-1
standarization makes mu=0,sd=1
cov(x,y)=cov(y,x)=1/nsum(for i = 1 n)(xi-mux)(yi-mux) where aij=aji in matrix form
if columns are standarize(lets say feathers f1 f2 f3..fn)
then cov(f1,f2)=1/n*f1Tf2(as mu are 0)
covariance of X matrix is XtX/n (if column stabdarize)
so for standarize columns of a matrix X the covariance of X is XtX/n[n= no of obs]

when there are a lot of dimension use pca and take it in 2-dimension to visualize

put model in production: Refer: http://scikit-learn.org/stable/modules/model_persistence.html


clustering: https://cs.wmich.edu/alfuqaha/summer14/cs6530/lectures/ClusteringAnalysis.pdf

jupyter login: login@123


netflix proze paper: Refer:https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf

Refer: http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/

Refer: https://github.com/seatgeek/fuzzywuzzy#usage

playground.tensorflow.org

http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf

Refer: https://en.wikipedia.org/wiki/Autoencoder

Refer: http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/

W2V optimization: https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/

Refer: https://medium.com/implodinggradients/tensorflow-or-keras-which-one-should-i-learn-5dd7fa3f9ca0

colab:
Refer: https://research.google.com/colaboratory/faq.html

Refer: https://colab.research.google.com/


Install TensorFlow

Refer: https://www.tensorflow.org/install/install_windows

Refer: https://www.tensorflow.org/get_started/

Refer: https://learningtensorflow.com/

Refer: https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd


https://www.tensorflow.org/api_docs/python/tf/argmax 

CNN:
Refer: https://en.wikipedia.org/wiki/Sobel_operator

Refer: https://en.wikipedia.org/wiki/Grayscale#/media/File:Beyoglu_4671_tricolor.png


Refer: http://cs231n.github.io/convolutional-networks/

Refer: http://www.iro.umontreal.ca/~bengioy/talks/DL-Tutorial-NIPS2015.pdf


Refer: https://www.quora.com/How-are-the-parameters-of-max-pooling-represented-in-the-weights-nodes-of-a-neural-network

Refer: https://world4jason.gitbooks.io/research-log/content/deepLearning/CNN/Model%20&%20ImgNet/lenet.html


Refer: https://en.wikipedia.org/wiki/ImageNet

Refer: https://www.kaggle.com/c/imagenet-object-detection-challenge

Refer: https://hazyresearch.github.io/snorkel/blog/tanda_figs/data_aug_basic.png

Convolution Layers in Keras
Refer:https://keras.io/layers/convolutional/
Refer: https://keras.io/layers/pooling/
Refer: https://keras.io/layers/core/#flatten
Refer: https://github.com/f00-/mnist-lenet-keras/blob/master/lenet.py

alexnet:
Refer: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
Refer: https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg
Refer: http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/notebook18.html

VGGNet
Refer: https://www.quora.com/What-is-the-VGG-neural-network
Refer: https://arxiv.org/pdf/1409.1556.pdf
Refer: https://github.com/fchollet/deep-learning-models/blob/master/vgg16.py

Residual Network.
Refer: https://arxiv.org/pdf/1512.03385.pdf
Refer: https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py

Inception Network.
Refer: http://www.ashukumar27.io/CNN-Inception-Network/
Refer: https://github.com/keras-team/keras/blob/master/keras/applications/inception_v3.py
Refer: https://arxiv.org/pdf/1512.00567.pdf

What is Transfer learning.
Refer: http://cs231n.github.io/transfer-learning/
Refer: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html


Code example: Cats vs Dogs. transfer learning
Refer: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html


Code Example: MNIST dataset.
Refer: https://drive.google.com/file/d/1I5kcAaQKEx0IwUNQvZdYkctwCcWFf81N


examples for YOLO:

1. https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006
2. Keras: https://github.com/experiencor/keras-yolo2
3. TensofrFlow: https://www.youtube.com/watch?v=4eIBisqx9_g


LSTM:
Refer: http://colah.github.io/posts/2015-08-Understanding-LSTMs/

GRUs.

Refer: https://www.slideshare.net/hytae/recent-progress-in-rnn-and-nlp-63762080

Refer: https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be

https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/

Code example : IMDB Sentiment classification
Refer: https://drive.google.com/file/d/1iWpQBiZO95pfOWLdaG6qKwA27d_Q-EDg/

https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model


Datasets. self driving car
Refer: https://github.com/commaai/research
Refer: https://github.com/udacity/self-driving-car/tree/master/datasets
Refer: http://data.apollo.auto/?locale=en-us&lang=en
Refer: https://github.com/SullyChen/Autopilot-TensorFlow

NVIDIA’s end to end CNN model.
Refer: model.py in zipped folder.
Refer: https://arxiv.org/pdf/1604.07316.pdf
Refer: https://devblogs.nvidia.com/deep-learning-self-driving-cars/


Extensions.
Refer: https://github.com/commaai/research

