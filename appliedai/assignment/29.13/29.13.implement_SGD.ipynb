{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implement SGD on bston dataset\n",
    "Dataset from sklearn load_boston\n",
    "\n",
    "The GD is theta=theta-alpha*derivative(cost function)\n",
    "equ=y=wtx+b; \n",
    "cost = (y-wtx-b)^2 \n",
    "determinant wrt w=> -2(y-wtx-b)x \n",
    "determinant wrt b => -2(y-wtx-b); \n",
    "in general : loss*  These are in vec notation\n",
    "\n",
    "h=np.dot(x,theta);\n",
    "loss=h-y;\n",
    "cost=np.sum(loss**2)/(2*m);\n",
    "gradient=np.dot(xt,loss)/m;\n",
    "theta=theta-alpha*gradient    \n",
    "\n",
    "# Objective\n",
    "Implement the model and compare the intercept and weights with sklearn\n",
    "\n",
    "# Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00,\n",
       "          0.00000000e+00,   5.38000000e-01,   6.57500000e+00,\n",
       "          6.52000000e+01,   4.09000000e+00,   1.00000000e+00,\n",
       "          2.96000000e+02,   1.53000000e+01,   3.96900000e+02,\n",
       "          4.98000000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)\n",
    "boston.data[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create all functions\n",
    "\n",
    "#m=no of obs,n=no of features\n",
    "def grad(x,y,theta,alpha=.000055,iteration=1000,k=200):\n",
    "  \n",
    "  #for SGD\n",
    "  m=x.shape[0]\n",
    "  \n",
    "  idx=np.random.randint(m,size=k)\n",
    "  x=x[idx,:]\n",
    "  y=np.random.choice(y,k)\n",
    "  #print('for SGD new size',x.shape,y.shape)\n",
    "\n",
    "  m,n=np.shape(x)\n",
    "  xt=x.transpose()\n",
    "  #print(\"x y, theta , m,n,shape before multiply\",x.shape,y.shape,theta.shape,m,n)\n",
    "  oldcost=0\n",
    "  bold=0\n",
    "  l=0\n",
    "  thetaprev=theta\n",
    "  prevalpha=alpha \n",
    "  optimumcost=0\n",
    "  ind=0   \n",
    "  for i in range(0,iteration):\n",
    "     l=l+1\n",
    "     h=np.dot(x,theta)\n",
    "     #print(\"\\nbefore loss h and y\",h.shape,y.shape)\n",
    "     loss=h-y\n",
    "     #print('loss',loss)\n",
    "     cost=np.sum(loss**2)/(2*k)\n",
    "     #if (oldcost^=0 & cost-oldcost<20):\n",
    "     #       break;\n",
    "     #if change is very slow increase alpha \n",
    "     b=(cost-oldcost)/oldcost\n",
    "     #print(\"At iteration %d Cost : %f oldcost : %f alpha %f cost compare %f\" %(i,cost,oldcost,alpha,b))\n",
    "     #if ((b>0 & bold<0) | (b<0 & bold>0)):\n",
    "     if((cost>oldcost) & (oldcost>0) & (ind==0)): \n",
    "         #set optimumcost only one time\n",
    "            ind=1\n",
    "            optimumcost=oldcost  \n",
    "            alpha=alpha/2\n",
    "            print(\"opt cost,ind\",optimumcost,ind)\n",
    "            theta=thetaprev\n",
    "            print('new alpha',alpha,'cost',cost,'old cost',oldcost)\n",
    "            continue   \n",
    "     elif ((b>-.05) & (ind==0)):\n",
    "            alpha=alpha*2\n",
    "     #elif (ind==1):\n",
    "     #       alpha=alpha*1.15\n",
    "     #       ind=2\n",
    "     \n",
    "     gradient=np.dot(xt,loss)/k\n",
    "     #print(\"\\ngradient\\n\",gradient)\n",
    "     theta=theta-alpha*gradient\n",
    "     aa=alpha*gradient\n",
    "     b=(cost-oldcost)/oldcost\n",
    "     oldcost=cost   \n",
    "     thetaprev=theta\n",
    "     prevalpha=alpha\n",
    "  return theta,cost \n",
    "     \n",
    "def data(x,y,k=10):    \n",
    "  x=np.append(x, np.ones([x.shape[0], 1]), axis=1)  #with intercept\n",
    "  #without intercept\n",
    "  n1=np.shape(x)[1]\n",
    "\n",
    "  theta=np.random.randn(n1)\n",
    "  print(\"theta passed shaped\",theta.shape,theta)\n",
    "  newtheta,cost=grad(x,y,theta)\n",
    "  print('coefficient of mymodel',newtheta)\n",
    "  return newtheta,cost  \n",
    "    \n",
    "def predict(x,newtheta):\n",
    "    x=np.append(x, np.ones([x.shape[0], 1]), axis=1) #with intercept\n",
    "    #without intercept\n",
    "    y=np.dot(x,newtheta)\n",
    "    return y\n",
    "\n",
    "def cost1(y_pred,y_test):\n",
    "    loss=y_pred-y_test\n",
    "    cost=np.sum(loss**2)/(2*y_test.shape[0])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model on boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta passed shaped (14,) [-0.34928575 -0.25273551  0.22934504  3.46410518 -1.1349958  -0.08180187\n",
      "  0.99810155 -0.61935544  0.78171907  1.39291839 -0.62273601 -0.06825148\n",
      " -1.26065196  0.12707627]\n",
      "opt cost,ind 46.4587664143 1\n",
      "new alpha 1.80224 cost 46.471094579 old cost 46.4587664143\n",
      "coefficient of mymodel [ -7.71569671   5.26571763   1.62570695  -1.8206091   -1.09320552\n",
      "  -0.41060108   0.29656759  -0.41699153   1.24613633   1.90826953\n",
      "  -0.41670367   0.35683023  -0.98397464  22.37734593]\n",
      "mymodel cost from the train 46.3899626879\n",
      "my model cost from the test 15.7528961505\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEgCAYAAACNV7VwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a04cfafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "y=np.array(boston.target)\n",
    "x=np.array(boston.data)\n",
    "from sklearn.preprocessing import normalize\n",
    "x = normalize(x, norm='l1', axis=0)\n",
    "\n",
    "x_train=x[0:450]\n",
    "x_test=x[451:505]\n",
    "y_train=y[0:450]\n",
    "y_test=y[451:505]\n",
    "#print(\"train test split\",x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "newtheta,cost=data(x_train,y_train)    \n",
    "print(\"mymodel cost from the train\",cost)\n",
    "#predict\n",
    "y_pred=predict(x_train,newtheta)\n",
    "cost=cost1(y_pred,y_train)\n",
    "\n",
    "y_pred=predict(x_test,newtheta)\n",
    "c=cost1(y_pred,y_test)\n",
    "\n",
    "#print(y_pred.shape,y_test.shape)\n",
    "print(\"my model cost from the test\",c)\n",
    "aa=pd.DataFrame({'type':['mymodel'],'train_cost':[cost],'test_cost':[c],'Coeff':[newtheta]})\n",
    "#print(aa)\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"my model Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Use SKLEAR model on boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 1) (54, 1) (450, 13) (54, 13)\n",
      "coefficient of sklearn model [ 22.72590254] [-0.03641638  0.10968696  0.01996954  0.10433229  0.03722955  0.05162522\n",
      "  0.03193732  0.05758237  0.01346549  0.02822044  0.03969217  0.05168383\n",
      "  0.0100268 ]\n",
      "sklearn Cost from train\n",
      "-0.00103925117368\n",
      "                                               Coeff  test_cost  train_cost  \\\n",
      "0  [-7.71569671429, 5.26571762679, 1.62570695438,...  15.752896   45.193189   \n",
      "0  [-0.0364163845211, 0.109686964888, 0.019969538...  -0.945312   -0.001039   \n",
      "\n",
      "      type  \n",
      "0  mymodel  \n",
      "0  sklearn  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use sklearn\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "x_train=pd.DataFrame(x_train)\n",
    "x_test=pd.DataFrame(x_test)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_test=pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "print(y_train.shape,y_test.shape,x_train.shape,x_test.shape)\n",
    "lm = SGDRegressor(fit_intercept=True)\n",
    "lm.fit(x_train, y_train)\n",
    "#print(lm.coef_)\n",
    "#y_test.reshape(-1,1)\n",
    "#np.reshape(y_test,54)\n",
    "#print(y_test.shape)\n",
    "y_pred = lm.predict(x_train)\n",
    "print('coefficient of sklearn model',lm.intercept_,lm.coef_)\n",
    "\n",
    "#c=cost1(y_pred,y_train)\n",
    "y_predtrain = lm.predict(x_train)\n",
    "print(\"sklearn Cost from train\")\n",
    "print(lm.score(x_train,y_train))\n",
    "\n",
    "#c1=cost1(y_pred,y_test)\n",
    "y_predtest = lm.predict(x_test)\n",
    "#print(\"sklearn Cost from test\",lm.score(y_predtest,y_test))\n",
    "bb=pd.DataFrame({'type':['sklearn'],'train_cost':[lm.score(x_train,y_train)],'test_cost':[lm.score(x_test,y_test)],'Coeff':[lm.coef_]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "#plt.scatter(y_test, y_pred)\n",
    "#plt.xlabel(\"Prices: $Y_i$\")\n",
    "#plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "#plt.title(\"sklearn Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "#plt.show()\n",
    "\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Score comparision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Coeff  test_cost  train_cost  \\\n",
      "0  [-7.71569671429, 5.26571762679, 1.62570695438,...  15.752896   45.193189   \n",
      "0  [-0.0364163845211, 0.109686964888, 0.019969538...  -0.945312   -0.001039   \n",
      "\n",
      "      type  \n",
      "0  mymodel  \n",
      "0  sklearn  \n"
     ]
    }
   ],
   "source": [
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn coeff [ 22.72590254] [-0.03641638  0.10968696  0.01996954  0.10433229  0.03722955  0.05162522\n",
      "  0.03193732  0.05758237  0.01346549  0.02822044  0.03969217  0.05168383\n",
      "  0.0100268 ]\n",
      "mymodel theta including intercept -7.71569671429 [  5.26571763   1.62570695  -1.8206091   -1.09320552  -0.41060108\n",
      "   0.29656759  -0.41699153   1.24613633   1.90826953  -0.41670367\n",
      "   0.35683023  -0.98397464  22.37734593]\n"
     ]
    }
   ],
   "source": [
    "print('sklearn coeff',lm.intercept_,lm.coef_)\n",
    "#aa[]\n",
    "print('mymodel theta including intercept',newtheta[0],newtheta[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "1. While trying learning rate of different value sometimes cost is going towards very hogh value, so tried with higher value\n",
    "2. After trying more iteration cost is going down with a very small alpha value\n",
    "3. sklearn model is performing better with cost close to 0 but my model cost is close to 30\n",
    "4. Best cost is achieved by different trial cost function\n",
    "5. theta are not changing much from initial random value (when alpha like .000005) \n",
    "6. when alpha taken like .05 , gradient is becoming too high. cost function is becoming inf, theta are becoming very high\n",
    "7. sklearn model is always getting global minimum but my model doesnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
