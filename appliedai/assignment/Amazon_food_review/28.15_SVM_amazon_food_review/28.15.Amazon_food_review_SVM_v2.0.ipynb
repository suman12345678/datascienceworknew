{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon food review dataset apply SVM\n",
    "\n",
    "Data set from https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "# Objective\n",
    "Try predicting review using SVM random and grid search and different value of lambda and C\n",
    "\n",
    "# Import data and libraries\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\suman\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.manifold import TSNE\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "con = sqlite3.connect('database.sqlite') \n",
    "\n",
    "#get only +ve and -ve review \n",
    "raw_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3\"\"\", con) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=raw_data\n",
    "# Score>3 a positive rating, and score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "\n",
    "filtered_data.sample(5)\n",
    "filtered_data['Score'].value_counts()\n",
    "\n",
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries for same profilename,userid, time, text and take first element \n",
    "sorted_data=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    42159\n",
       "negative     7841\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take only 50000 \n",
    "_ , clean_data = train_test_split(sorted_data, test_size = 50000, random_state=0,stratify = sorted_data['Score'] )\n",
    "clean_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "440016    b'pumpkin seed delici healthi snack subscrib s...\n",
       "253343    b'tast delici cheaper site easili mix water sh...\n",
       "Name: CleanedText, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean html tag and punctuation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "#substitute html tag and punctuation\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "#print(sno.stem('tasty'))\n",
    "\n",
    "i=0\n",
    "str1=' '\n",
    "mystop={'of','four','one','would'}\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "#Create new catagory as Cleanedtext after removing htmltag and punctuation and uppercase and word length >2\n",
    "for sent in clean_data['Text'].values:\n",
    "    #change later\n",
    "    #sent=sent[:20]\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if((cleaned_words.lower() not in stop) & (cleaned_words.lower() not in mystop)):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (clean_data['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(clean_data['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1\n",
    " \n",
    "clean_data['CleanedText']=final_string\n",
    "print(clean_data.shape)\n",
    "#Sort data on timestamp\n",
    "clean_data=clean_data.sort_values(by=['Time'],ascending=False)\n",
    "#clean_data\n",
    "clean_data['CleanedText'].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X_train, X_test, y_train , y_test  (35000,) (15000,) (35000,) (15000,)\n",
      "positive and negative review in train and test\n",
      " positive    29732\n",
      "negative     5268\n",
      "Name: Score, dtype: int64 \n",
      " positive    12427\n",
      "negative     2573\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x=clean_data['CleanedText'].values\n",
    "y = clean_data['Score']\n",
    "n=x.shape[0]\n",
    "n1=int(n*.3)\n",
    "X_test_raw = x[0:n1]\n",
    "X_train_raw= x[n1:n+1]\n",
    "y_test=y[0:n1]\n",
    "y_train=y[n1:n+1]\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train_raw.shape, X_test_raw.shape,y_train.shape,y_test.shape)\n",
    "print(\"positive and negative review in train and test\\n\",y_train.value_counts(),\"\\n\",y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BOW and try linear kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 23013) (15000, 23013)\n"
     ]
    }
   ],
   "source": [
    "#now convert CleanedText to TDM\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "X_train = count_vect.fit_transform(X_train_raw)\n",
    "\n",
    "#use the same vectors to convert test data\n",
    "X_test=count_vect.transform(X_test_raw)\n",
    "print(X_train.get_shape(),X_test.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X_train, X_test, y_train , y_test  (35000, 23013) (15000, 23013) (35000,) (15000,)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Use scale of train and apply to test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "encoded_column_vector = label_binarize(y_train, classes=['negative','positive']) # negative will be 0 and positive will be 1\n",
    "encoded_labels = np.ravel(encoded_column_vector) # Reshape array\n",
    "y_train=encoded_labels\n",
    "\n",
    "encoded_column_vector = label_binarize(y_test, classes=['negative','positive']) # negative will be 0 and positive will be 1\n",
    "encoded_labels = np.ravel(encoded_column_vector) # Reshape array\n",
    "y_test=encoded_labels\n",
    "\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took for preprocessing the text : 0.00013898124608447066 seconds\n",
      "Best parameters with linear karnel and grid search\n",
      " SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Time took for preprocessing the text : 982.6724622559013 seconds\n",
      "confusion matrix\n",
      " Predicted      1    All\n",
      "Actual                 \n",
      "0           2573   2573\n",
      "1          12427  12427\n",
      "All        15000  15000\n",
      "Test accuracy using linear kernel 0.8284666666666667\n"
     ]
    }
   ],
   "source": [
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import validation_curve\n",
    "       \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "#alpha=[.001,.01,.1,1,10,100]\n",
    "kernel=['linear']\n",
    "gamma=['auto']\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "#tuned_parameters=dict(alpha=alpha, kernel=kernel,gamma=gamma)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#Using GridSearchCV\n",
    "#model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "#using hinge loss with SGD classifier is more performant\n",
    "import time\n",
    "start_time=time.clock()\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "print('Time took for preprocessing the text :',time.clock() - start_time, \"seconds\")\n",
    "#SGDClassifier( class_weight='balanced', alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with linear karnel and grid search\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "start_time=time.clock()\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "print('Time took for preprocessing the text :',time.clock() - start_time, \"seconds\")\n",
    "\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "aa=pd.DataFrame({'type':['Grid search BOW'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel\",model.score(X_test, y_test))\n",
    "start_time=time.clock()\n",
    "\n",
    "C=[1,10,50,100,150,200,500]\n",
    "param_range=[1,10,50,100,150,200,500]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(), X_train, y_train, param_name=\"C\",param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With linear SVM for different C value\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(1,500)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print('Time took for preprocessing the text :',time.clock() - start_time, \"seconds\")\n",
    "\n",
    "\n",
    "#****************************************\n",
    "#TRY SGD classifier for better performance\n",
    "alpha=[.001,.01,.1,1,10,100]\n",
    "tuned_parameters=dict(alpha=alpha)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "start_time=time.clock()\n",
    "model = GridSearchCV(SGDClassifier(penalty='l2',loss='hinge'),tuned_parameters, scoring = 'f1', cv=5)\n",
    "print('Time took for preprocessing the text SGDclassifier grid search:',time.clock() - start_time, \"seconds\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "optimumalpha=model.best_estimator_.alpha\n",
    "#build model with best parameter\n",
    "model = SGDClassifier(penalty='l2',loss='hinge',alpha=optimumalpha)\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "bb=pd.DataFrame({'type':['SGD BOW'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':['na']})\n",
    "aa=aa.append(bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "C=[.1,.5,.8,1,2]\n",
    "kernel=['linear']\n",
    "gamma=['auto']\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using linear kernel and random search \\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix \\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "bb=pd.DataFrame({'type':['Random Search BOW'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "print(aa)\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "   \n",
    "    \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search BOW'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel\",model.score(X_test, y_test))\n",
    "\n",
    "C=[.1,.5,.8,1,2,5]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search \\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.9,.7,.5,.3,.1,1,2,5]\n",
    "param_range=[.9,.7,.5,.3,.1,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With linear SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.1,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "final_counts = tf_idf_vect.fit_transform(X_train_raw)\n",
    "#use the same vectors to convert test data\n",
    "X_test=final_counts.transform(X_test_raw)\n",
    "print(X_train.get_shape(),X_test.get_shape())\n",
    "#Use scale of train and apply to test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "  \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search using TFIDF\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel TFIDF\",model.score(X_test, y_test))\n",
    "\n",
    "C=[.1,.5,.8,1,2,5,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search TFIDF\\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix test\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "bb=pd.DataFrame({'type':['Random search TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "#******************************\n",
    "#TRY SGD classifier for better performance\n",
    "alpha=[.001,.01,.1,1,10,100]\n",
    "tuned_parameters=dict(alpha=alpha)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "start_time=time.clock()\n",
    "model = GridSearchCV(SGDClassifier(penalty='l2',loss='hinge'),tuned_parameters, scoring = 'f1', cv=5)\n",
    "print('Time took for preprocessing the text SGDclassifier grid search:',time.clock() - start_time, \"seconds\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "optimumalpha=model.best_estimator_.alpha\n",
    "#build model with best parameter\n",
    "model = SGDClassifier(penalty='l2',loss='hinge',alpha=optimumalpha)\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "bb=pd.DataFrame({'type':['SGD TFIDF'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':['na']})\n",
    "aa=aa.append(bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.05,.03,.02,.01,1,2,5]\n",
    "param_range=[.05,.03,.02,.01,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.5,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy with C with optimum gamma\n",
    "C=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "param_range=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',gamma=optimumgamma), X_train, y_train, param_name=\"C\", \\\n",
    "                                              param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different C value for optimum gamma\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.01,20)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AVG W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "import gensim\n",
    "#convert W2V train data\n",
    "i=0\n",
    "#create a list of list to be used in W2V \n",
    "list_of_sent_train=[]\n",
    "for sent in X_train_raw:  #clean_data['CleanedText'].values:\n",
    "    filtered_sentence=[]\n",
    "    #sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        #for cleaned_words in cleanpunc(w).split():\n",
    "         for cleaned_words in w.split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower().decode('utf8'))\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_train.append(filtered_sentence)\n",
    "#convert each sentence's words to a vector of 50 dimension. Dont construct vec if word doesnot occur 5 times. And for each word construct 50 dimension vector\n",
    "#and 4 core processor\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent_train,min_count=5,size=50, workers=4)   \n",
    "\n",
    "# average Word2Vec\n",
    "# for each sentence make average of vectors by (vectors of each words)/(total no of words)\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent_train: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_train.append(sent_vec)  \n",
    "\n",
    "    \n",
    "#convert W2V test data\n",
    "i=0\n",
    "#create a list of list to be used in W2V \n",
    "list_of_sent_test=[]\n",
    "for sent in X_test_raw:  #clean_data['CleanedText'].values:\n",
    "    filtered_sentence=[]\n",
    "    #sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        #for cleaned_words in cleanpunc(w).split():\n",
    "         for cleaned_words in w.split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower().decode('utf8'))\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_test.append(filtered_sentence)\n",
    "#convert each sentence's words to a vector of 50 dimension. Dont construct vec if word doesnot occur 5 times. And for each word construct 50 dimension vector\n",
    "#and 4 core processor\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent_test,min_count=5,size=50, workers=4)   \n",
    "\n",
    "# average Word2Vec\n",
    "# for each sentence make average of vectors by (vectors of each words)/(total no of words)\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_test.append(sent_vec)  \n",
    "\n",
    "# try\n",
    "X_train = pd.DataFrame(sent_vectors_train)\n",
    "X_test = pd.DataFrame(sent_vectors_test)\n",
    "\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "  \n",
    "# Use grid search\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search using TFIDF\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search AVG W2V'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "print(\"Test accuracy using linear kernel AVG W2V\",model.score(X_test, y_test))\n",
    "C=[.1,.5,.8,1,2,5,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search AVG W2V\\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "bb=pd.DataFrame({'type':['Random search AVG W2V'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# Plot\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.05,.03,.02,.01,1,2,5]\n",
    "param_range=[.05,.03,.02,.01,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.5,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy with C with optimum gamma\n",
    "C=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "param_range=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',gamma=optimumgamma), X_train, y_train, param_name=\"C\", \\\n",
    "                                              param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different C value for optimum gamma\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.01,20)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#******************************\n",
    "#TRY SGD classifier for better performance\n",
    "alpha=[.001,.01,.1,1,10,100]\n",
    "tuned_parameters=dict(alpha=alpha)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "start_time=time.clock()\n",
    "model = GridSearchCV(SGDClassifier(penalty='l2',loss='hinge'),tuned_parameters, scoring = 'f1', cv=5)\n",
    "print('Time took for preprocessing the text SGDclassifier grid search:',time.clock() - start_time, \"seconds\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "optimumalpha=model.best_estimator_.alpha\n",
    "#build model with best parameter\n",
    "model = SGDClassifier(penalty='l2',loss='hinge',alpha=optimumalpha)\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "bb=pd.DataFrame({'type':['SGD AVGW2V'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':['na']})\n",
    "aa=aa.append(bb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AVG W2V TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "final_tf_idf=tf_idf_vect.fit_transform(X_train_raw)\n",
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors_train = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "#calculate avg tfidf score for each sentences \n",
    "for sent in list_of_sent_train: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]#calculate w2v for each word\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = final_tf_idf[row, tfidf_feat.index(word)]#get tfidf score of each word \n",
    "            sent_vec += (vec * tf_idf) # multiply vec with tfidf of each word and cumulative add of words in each sentence\n",
    "            weight_sum += tf_idf # also add tfidf sums in each sentence\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_train.append(sent_vec)\n",
    "    row += 1\n",
    "#tfidf_sent_vectors.\n",
    "\n",
    "# do for test\n",
    "final_tf_idf=tf_idf_vect.transform(X_test_raw)\n",
    "tfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "#calculate avg tfidf score for each sentences \n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]#calculate w2v for each word\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = final_tf_idf[row, tfidf_feat.index(word)]#get tfidf score of each word \n",
    "            sent_vec += (vec * tf_idf) # multiply vec with tfidf of each word and cumulative add of words in each sentence\n",
    "            weight_sum += tf_idf # also add tfidf sums in each sentence\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_test.append(sent_vec)\n",
    "    row += 1\n",
    "\n",
    "X_train = pd.DataFrame(tfidf_sent_vectors_train)\n",
    "X_test = pd.DataFrame(tfidf_sent_vectors_test)\n",
    "print('size of X_train, X_test, y_train , y_test ',X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "\n",
    "# Build model with linear kernel with random and grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "    \n",
    "  \n",
    "# Use grid search for L2\n",
    "C=[.1,1,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters with rbf karnel and grid search using TFIDF\\n',model.best_estimator_)\n",
    "#print('Model test score', model.score(X_test, y_test))\n",
    "\n",
    "optimumc=model.best_estimator_.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.best_estimator_.gamma\n",
    "\n",
    "#print(type(X_train),type(y_train))\n",
    "\n",
    "#build model with best parameter\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Grid search AVG W2V TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy using linear kernel TFIDF\",model.score(X_test, y_test))\n",
    "\n",
    "C=[.1,.5,.8,1,2,5,10,100]\n",
    "kernel=['rbf']\n",
    "gamma=[.01,.1,1,10]\n",
    "\n",
    "tuned_parameters=dict(C=C, kernel=kernel,gamma=gamma)\n",
    "\n",
    "#Using random search\n",
    "model = RandomizedSearchCV(svm.SVC(), tuned_parameters, random_state=1, scoring = 'f1', cv=5)\n",
    "\n",
    "print('Best parameters using rbf kernel and random search TFIDF\\n',model.estimator)\n",
    "#build model with best parameter\n",
    "optimumc=model.estimator.C\n",
    "#optimumkernel=model.best_estimator_.kernel\n",
    "optimumgamma=model.estimator.gamma\n",
    "\n",
    "\n",
    "model = svm.SVC(C=optimumc,gamma=optimumgamma)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "print('confusion matrix\\n',mat)\n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "bb=pd.DataFrame({'type':['Random search AVG W2V TFIDF'],'kernel':['rbf'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':[model.gamma]})\n",
    "aa=aa.append(bb)\n",
    "\n",
    "# Check test accuracy\n",
    "print(\"Test accuracy\",model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# Plot\n",
    "# plot accuracy with gamma with optimum c\n",
    "gamma=[.05,.03,.02,.01,1,2,5]\n",
    "param_range=[.05,.03,.02,.01,1,2,5]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',C=optimumc), X_train, y_train, param_name=\"gamma\", \\\n",
    "                                              param_range=gamma,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different gamma value for optimum C value\")\n",
    "plt.xlabel(\"gamma value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.5,5)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy with C with optimum gamma\n",
    "C=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "param_range=[.01,.9,.7,.5,.3,.1,1,2,5,10,20]\n",
    "train_scores, test_scores = validation_curve(svm.SVC(kernel='rbf',gamma=optimumgamma), X_train, y_train, param_name=\"C\", \\\n",
    "                                              param_range=C,cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"red\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, color=\"green\")\n",
    "plt.title(\"Validation Curve With kernel SVM for different C value for optimum gamma\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlim(.01,20)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#******************************\n",
    "#TRY SGD classifier for better performance\n",
    "alpha=[.001,.01,.1,1,10,100]\n",
    "tuned_parameters=dict(alpha=alpha)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "start_time=time.clock()\n",
    "model = GridSearchCV(SGDClassifier(penalty='l2',loss='hinge'),tuned_parameters, scoring = 'f1', cv=5)\n",
    "print('Time took for preprocessing the text SGDclassifier grid search:',time.clock() - start_time, \"seconds\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "optimumalpha=model.best_estimator_.alpha\n",
    "#build model with best parameter\n",
    "model = SGDClassifier(penalty='l2',loss='hinge',alpha=optimumalpha)\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "mat=pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0] ;fp=mat.iloc[0,1];fn=mat.iloc[1,0];precision=tp/(tp+fp) \n",
    "recall=tp/(tp+fn) \n",
    "fscoretest=2*precision*recall/(precision+recall)\n",
    "pred=model.predict(X_train)\n",
    "mat=pd.crosstab(y_train, pred, rownames=['Actual'], colnames=['Predicted'], margins=True) \n",
    "tp=mat.iloc[1,1] ;tn=mat.iloc[0,0];fp=mat.iloc[0,1] ;fn=mat.iloc[1,0] ;precision=tp/(tp+fp);\n",
    "recall=tp/(tp+fn) \n",
    "fscoretrain=2*precision*recall/(precision+recall)\n",
    "bb=pd.DataFrame({'type':['SGD AVGW2V TFIDF'],'kernel':['linear'],'accuracy_train':[model.score(X_train,y_train)], \\\n",
    "                 'fscore_train':[fscoretrain],'accuracy_test':[model.score(X_test,y_test)],'fscore_test':[fscoretest],\\\n",
    "                 'C':[model.C],'gamma':['na']})\n",
    "aa=aa.append(bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Second graph x axis name is mentioned wrongly[copy paste error for all graph]. Please consider that. If I execute again it will take 8-9 hrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "The below steps are taken to complete this\n",
    "Only !=3 reviews are taken Mark >3 as positive and <3 as negative. Sort data as per product id in ascending order Deduplication of entries for same profilename,userid, time, text and take first element Get stratified sampling of 10k data Clean html and punctuation Convert to uppercase and word<3 are rejected data sorted on time Split the data in train and test to 70:30\n",
    "\n",
    "BOW\n",
    "BOW BOW vec created using train data test data is converted using above X is standarize on train and same applied to test y is converted to 1 and 0 from positive and negative \n",
    "\n",
    "do grid search and random search for different value of kernel and C best model is established with best hyperparameter. model metric is stored in dataframe and crosstable is printed.Plot cv error with C and penalty\n",
    "\n",
    "TFIDF \n",
    "form tfidf vec using train same is used in test to convert rest are same\n",
    "\n",
    "\n",
    "AVG W2V \n",
    "gensim is used to convert train and test text to \n",
    "\n",
    "W2V AVG TFIDF\n",
    "form tfidf vec using train same is used in test to convert. TFIDF and gensim is used to convert test data. rest are same\n",
    "\n",
    "The scores are below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
